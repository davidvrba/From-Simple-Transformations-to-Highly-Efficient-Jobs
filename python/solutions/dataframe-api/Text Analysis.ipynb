{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a6dc01-1c5d-44b1-8722-fad567149f8e",
   "metadata": {},
   "source": [
    "## Do high-reputation users tend to write more readable content?\n",
    "\n",
    "In this notebook we will see how to use a Python library to analyze text using User Defined functions.\n",
    "\n",
    "You will:\n",
    "* Do some basic text cleaning of the answers\n",
    "* Compute readability of answers\n",
    "* Join answers with users\n",
    "* Compute average readability per user\n",
    "* Compute correlation between user reputation and avarage readability of his answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f47fab-1051-43ed-a21c-9e2cb06be5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textstat import flesch_reading_ease\n",
    "import os\n",
    "import re\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, udf, desc, corr, avg, first, regexp_replace, trim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca954d5d-8bda-4122-b6d5-d8016998e7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('Text Analysis')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef48d9-650d-4e17-938b-2fa4f72118d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "answers_input_path = os.path.join(project_path, 'data/answers')\n",
    "\n",
    "users_input_path = os.path.join(project_path, 'data/users')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe0dd1d-009e-4d96-9188-d9a0eda72dc8",
   "metadata": {},
   "source": [
    "## Compute readability of each answer\n",
    "\n",
    "Hint\n",
    "* we will work with the answers dataset. Check the body of the answers, you will see that they contain html tags and possible other characters that is good to remove for the analysis\n",
    "* implement a function that will do (at least some basic) text cleaning\n",
    "  * this function can be a native wrapper over [regexp_replace](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_replace.html) that can be used to remove the unwanted characters\n",
    "* implement a User Defined Function that will use the `flesch_reading_ease` function from the `textstat` Python library\n",
    "  * for more info about textstat see the [docs](https://pypi.org/project/textstat/)\n",
    "  * for more info about the metodology to compute readability using Flesh Reading Ease see [wiki](https://simple.wikipedia.org/wiki/Flesch_Reading_Ease)\n",
    "* Note:\n",
    "  * if you want to go for some more robust text cleaning and the regexp_replace is not sufficient or to cumbersome for you, you can use Python functionality for the text cleaning and make it part of your UDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38459f78-8b7d-424d-8df4-4866a4deab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the input dataframes for answers and users:\n",
    "\n",
    "answersDF = spark.read.parquet(answers_input_path)\n",
    "\n",
    "usersDF = spark.read.parquet(users_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d39708-53f7-408b-939a-a9fc87095de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the text cleaning function:\n",
    "\n",
    "def clean_text(df: DataFrame) -> DataFrame:\n",
    "    return (\n",
    "        df.withColumn(\"body\", regexp_replace(\"body\", \"<[^>]*>\", \"\"))  # Remove HTML tags\n",
    "        .withColumn(\"body\", regexp_replace(\"body\", \"\\\\\\\\n|\\\\\\\\r|\\\\\\\\t|\\\\n|\\\\r|\\\\t\", \" \"))  # Remove escape characters\n",
    "        .withColumn(\"body\", regexp_replace(\"body\", \"\\\\s+\", \" \"))  # Collapse multiple spaces\n",
    "        .withColumn(\"body\", trim(\"body\"))  # Trim leading/trailing spaces\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed92138-56d9-4fff-a3b8-b98fca8f10f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the udf to compute the readability\n",
    "\n",
    "@udf('double')\n",
    "def readability_udf(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    return flesch_reading_ease(text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cda37d-e067-4571-b4d5-5b6eec26a44b",
   "metadata": {},
   "source": [
    "## Compute correlation between average readability and reputation of users\n",
    "\n",
    "Hint:\n",
    "* apply the udf to compute the readability\n",
    "* join answers with users to bring the info about reputation\n",
    "* group by users and compute avg readability for each user (this should describe how readable are on average the published answers for each user)\n",
    "* compute the Pearson correlation coefficient for average readability and reputation\n",
    "  * see [docs](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.corr.html) for corr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ae262-d4f6-473d-9219-2a42d29e0383",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    answersDF\n",
    "    .transform(clean_text)\n",
    "    .withColumn('readability', readability_udf(col('body')))\n",
    "    .join(usersDF, 'user_id')\n",
    "    .groupBy('user_id')\n",
    "    .agg(\n",
    "        avg('readability').alias('avg_readability'),\n",
    "        first('reputation').alias('reputation')\n",
    "    )\n",
    "    .agg(corr('avg_readability', 'reputation'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d77364-22cf-458b-89d1-08e17742a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
