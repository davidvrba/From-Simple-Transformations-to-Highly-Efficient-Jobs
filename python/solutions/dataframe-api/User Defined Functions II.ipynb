{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical modeling\n",
    "\n",
    "In this notebook we will see how user defined functions can be used for statistical modeling using [scipy](http://scipy.github.io/devdocs/reference/index.html) package. We will also see how to implement Pandas UDF which has better performace than vanilla UDF because it can laverage [Apache Arrow](https://arrow.apache.org/) under the hood for exchanging the data and vectorized execution that is supported by the scipy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, lit, count, year, pandas_udf, avg\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "from scipy.stats import poisson\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('UDFs II')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "answers_input_path = os.path.join(project_path, 'data/answers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "For each user compute probability that the user is going to answer 5 questions in the next year. Use simple model based on poisson distribution.\n",
    "\n",
    "1. Create a DataFrame with two cols: `user_id`, `answers`, where the second is the average number of questions the user answered per year.\n",
    "2. Implement UDF that will use [poisson](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html) distribution from scipy package to compute the probability that if the user answered <i>n</i> questions per year, he will answer 5 questions in the next year\n",
    "3. Implement the UDF again, but this time as Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need answers dataset:\n",
    "\n",
    "answersDF = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('path', answers_input_path)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answersDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create input DataFrame\n",
    "\n",
    "* filter for rows where `user_id` is not null\n",
    "* compute average number of answers per user per year\n",
    " * group by user and year\n",
    " * use count to see how many questions each user answered in each year\n",
    " * group by again but now only per user\n",
    " * compute the average per year for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = (\n",
    "    answersDF\n",
    "    .filter(col('user_id').isNotNull())\n",
    "    .withColumn('creation_year', year('creation_date'))\n",
    "    .groupBy(\n",
    "        'creation_year', 'user_id',\n",
    "    )\n",
    "    .agg(\n",
    "        count('*').alias('answers')\n",
    "    )\n",
    "    .groupBy('user_id')\n",
    "    .agg(\n",
    "        avg('answers').alias('answers')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define UDF:\n",
    "\n",
    "Hint:\n",
    "* the return type will be float, since we will compute probability\n",
    "* use pmf function of the [poisson](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html) in scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf('float')\n",
    "def get_probability(k, year_average):\n",
    "    return float(poisson.pmf(k, year_average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    input_df\n",
    "    .withColumn('probability', get_probability(lit(5), col('answers')))\n",
    "    \n",
    ").show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try it with Pandas\n",
    "\n",
    "* create local Pandas dataframe with input data\n",
    "* pass a local Pandas series to poisson to see what it returns\n",
    "\n",
    "Hint:\n",
    "* create a pandas series from pandas dataframe as `local_data['answers']`, where local_data is pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data = input_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It returns numpy array\n",
    "\n",
    "poisson.pmf(5, local_data['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily create a pandas series from it:\n",
    "\n",
    "pd.Series(poisson.pmf(5, local_data['answers']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pandas udf:\n",
    "\n",
    "@pandas_udf('float')\n",
    "def get_probability_pd(k, year_average):\n",
    "    return pd.Series(poisson.pmf(k, year_average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the UDF:\n",
    "\n",
    "(\n",
    "    input_df\n",
    "    .withColumn('probability', get_probability_pd(lit(5), col('answers')))\n",
    ").show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the performace for both UDFs\n",
    "\n",
    "Hint\n",
    "* run the query with the noop format\n",
    "* check the execution time in SparkUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution of vanilla UDF:\n",
    "\n",
    "(\n",
    "    input_df\n",
    "    .withColumn('probability', get_probability(lit(5), col('answers')))\n",
    "    .write\n",
    "    .mode('overwrite')\n",
    "    .format('noop')\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution of Pandas UDF:\n",
    "\n",
    "(\n",
    "    input_df\n",
    "    .withColumn('probability', get_probability_pd(lit(5), col('answers')))\n",
    "    .write\n",
    "    .mode('overwrite')\n",
    "    .format('noop')\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
