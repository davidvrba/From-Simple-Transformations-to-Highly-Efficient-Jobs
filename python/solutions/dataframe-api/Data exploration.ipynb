{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "\n",
    "The goal of this notebook is to get familiar with the datasets that will be used throughout the training. \n",
    "\n",
    "Explore these three dataset:\n",
    "* questions (Json format)\n",
    "* answers (Parquet format)\n",
    "* users (Parquet format)\n",
    "\n",
    "\n",
    "1. For each of them:\n",
    "  * see the schema\n",
    "  * see 10 records\n",
    "  * find the total count\n",
    "    \n",
    "2. For users find out how many distinct locations we have\n",
    "3. Who asked the question with highest score?\n",
    "4. Is the answer that has the highest score accepted?\n",
    "5. Identify the question with the most occurrences of the word `spark` in the body, case-insensitive.\n",
    "6. Compute response time for spark-related question that has answer with highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, desc, count, regexp_count, lower, lit\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('Data inspection')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the datasets:\n",
    "\n",
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "questions_input_path = os.path.join(project_path, 'data/questions-json')\n",
    "\n",
    "answers_input_path = os.path.join(project_path, 'data/answers')\n",
    "\n",
    "users_input_path = os.path.join(project_path, 'data/users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersDF = spark.read.parquet(users_input_path)\n",
    "\n",
    "questionsDF = spark.read.json(questions_input_path)\n",
    "\n",
    "answersDF = spark.read.parquet(answers_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Explore the data: Check the schemas, counts and some records\n",
    "\n",
    "Hint:\n",
    "* use `printSchema`, `count`, `show`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersDF.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionsDF.show(n=10, truncate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionsDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answersDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answersDF.show(n=10, truncate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answersDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For users find out how many distinct locations we have\n",
    "\n",
    "Hint:\n",
    "* use `distinct` or `dropDuplicates`\n",
    "* docs for [distinct](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.distinct.html#pyspark.sql.DataFrame.distinct)\n",
    "* docs for [dropDuplicates](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.dropDuplicates.html#pyspark.sql.DataFrame.dropDuplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersDF.select('location').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Who asked the question with highest score?\n",
    "\n",
    "Hint:\n",
    "* [join](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.join.html#pyspark.sql.DataFrame.join) questions with users on the `user_id` column\n",
    "* use [orderBy](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.orderBy.html#pyspark.sql.DataFrame.orderBy) + [desc](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.desc.html#pyspark.sql.functions.desc)\n",
    "* after sorting select only the question score and the user specific attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    questionsDF\n",
    "    .join(usersDF.alias('users'), 'user_id')\n",
    "    .orderBy(desc('score'))\n",
    "    .select('users.*', 'score')\n",
    ").show(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Is the answer that has the highest score accepted?\n",
    "\n",
    "Hint:\n",
    "* join answers with questions\n",
    "* sort in desc order by the answers score to get the answer with highest score\n",
    "* check the `accepted_answer_id` column: if the value is the same as the value in `answer_id` colum then it is accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    answersDF.alias('answers')   \n",
    "    .join(questionsDF.alias('questions'), 'question_id', 'left')\n",
    "    .orderBy(desc('answers.score'))\n",
    "    .select('answers.question_id', 'answer_id', 'accepted_answer_id')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Identify the question with the most occurrences of the word `spark` in the body, case-insensitive.\n",
    "\n",
    "Hint:\n",
    "* check the functions:\n",
    "  * [regexp_count](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_count.html)\n",
    "  * [lower](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lower.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    questionsDF\n",
    "    .withColumn('spark_count', regexp_count(lower(col('body')), lit('spark')))\n",
    "    .orderBy(desc('spark_count'))\n",
    "    .select('question_id', 'title', 'body', 'spark_count')\n",
    ").show(truncate=50, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compute response time for spark-related question that has the answer with highest score\n",
    "\n",
    "Hint:\n",
    "* in our context spark-related means: Find questions where at least one tag contains expression `spark`\n",
    "* identify which of these questions has answer with the highest score\n",
    "* for this particular question with highest score compute the response time (how long it took between posting the question and posting its answer) and convert it to minutes.\n",
    "* what is the question about? Apart from the response time, select also the title of the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    questionsDF.withColumn('creation_date', col('creation_date').cast('timestamp'))\n",
    "    .filter(col('tags').like('%spark%'))\n",
    "    .alias('questions')\n",
    "    .join(answersDF.alias('answers'), 'question_id')    \n",
    "    .orderBy(desc('answers.score'))\n",
    "    .withColumn('response_time', (col('answers.creation_date').cast('long') - col('questions.creation_date').cast('long')) / 60)\n",
    "    .select('title', 'answers.creation_date', 'questions.creation_date', 'response_time')              \n",
    ").show(truncate=70, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
