{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Analytics\n",
    "\n",
    "In this notebook you will answer 2 basic analytical questions about the data and visualise the result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, window, count, unix_timestamp, when, lit, ceil\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('Interactive Analytics I')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "answers_input_path = os.path.join(project_path, 'data/answers')\n",
    "\n",
    "questions_input_path = os.path.join(project_path, 'output/questions-transformed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task I\n",
    "\n",
    "* Find out how many answers are being produced per week\n",
    "* Plot the time evolution: on the x axis have date dimmension, on the y axis have number of answers per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answersDF = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('path', answers_input_path)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answersDF.show(truncate=25, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Group the data</b>\n",
    "\n",
    "Hint:\n",
    "* use groupBy(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedDF = (\n",
    "    answersDF\n",
    "    .filter(col('user_id').isNotNull())\n",
    "    .groupBy(\n",
    "        window('creation_date', \"1 week\")\n",
    "    )\n",
    "    .agg(\n",
    "        count('*').alias('answers')\n",
    "    )\n",
    "    .withColumn('date', col('window.start').cast('date'))\n",
    "    .orderBy('window')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedDF.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Visualise the data:</b>\n",
    "\n",
    "Hint\n",
    "* convert the aggregated data to Pandas dataframe using toPandas()\n",
    "* use ploting options of Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data = groupedDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data.plot(\n",
    "    x='date', y='answers', figsize=(12, 6), \n",
    "    title='Number of answers per week',\n",
    "    legend=False\n",
    "    \n",
    ")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of answers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task II\n",
    "\n",
    "* Compute the response time\n",
    " * for each question compute the time it took to have accepted answer\n",
    " * consider only questions with accepted answer\n",
    "* Plot number of answered questions as a function of response time\n",
    " * choose hour as time unit\n",
    " * create a bar chart (too see how many questions were answered within one hour, within 2 hours and so on)\n",
    " * chreta a cumulative sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionsDF = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('path', questions_input_path)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Compute response time:</b>\n",
    "\n",
    "Hint:\n",
    "* join questions with answers\n",
    "* use unix_timestamp to compare the times\n",
    "* convert to hours\n",
    "* ceil the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data = (\n",
    "    questionsDF.alias('questions')\n",
    "    .join(answersDF.alias('answers'), questionsDF['accepted_answer_id'] == answersDF['answer_id'])\n",
    "    .select(\n",
    "        col('questions.tags'),\n",
    "        col('questions.creation_date').alias('question_time'),\n",
    "        col('questions.title'),\n",
    "        col('answers.creation_date').alias('answer_time')\n",
    "    )\n",
    "    .withColumn('response_time', unix_timestamp('answer_time') - unix_timestamp('question_time'))\n",
    "    .filter(col('response_time') > 0)\n",
    "    .withColumn('hours', ceil(col('response_time') / 3600))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Aggregate the data and visualise</b>\n",
    "\n",
    "Hint:\n",
    "* group by hour\n",
    "* count\n",
    "* convert to Pandas\n",
    "* visualize (take first 50 records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data_grouped = (\n",
    "    hourly_data\n",
    "    .groupBy('hours')\n",
    "    .agg(count('*').alias('cnt'))\n",
    "    .orderBy('hours')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data_local = hourly_data_grouped.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data_local.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For bar chart you can use df.plot.bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data_local.head(50).plot.bar(\n",
    "    x='hours', y='cnt', figsize=(12, 6), \n",
    "    title='Response time of questions',\n",
    "    legend=False\n",
    "    \n",
    ")\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Number of answered questions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cumulative sum you can use df['col'].comsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data_local.head(50)['cnt'].cumsum().plot(\n",
    "    figsize=(12, 6),\n",
    "    title='Cumulative size of answered questions'\n",
    ")\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Number of answered questions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
