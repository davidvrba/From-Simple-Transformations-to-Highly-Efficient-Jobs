{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task I: Build a recommendation system\n",
    "\n",
    "* Suppose users are eager to answer some questions, but there is a lot of questions and it is not easy to search for relevant one. \n",
    "* We have a list of questions that already have some answers but non of them was accepted so they still wait for more precise/accurate answer\n",
    "* Try to build a system that will recommend for each of these questions a set of 10 users that are likely to answer them\n",
    "* Use the ALS algorithm with implicit ratings and assume that the rating can be modeled by the score information\n",
    "    * Some questions have been answered by multiple users and these answers gained some score (even though they may have not been accepted)\n",
    "    * We will assume that users with similar knowladge/interest will gain similar score for their answer. So for particular question we will recommend a user depending on other users that answered this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('RS')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "answers_input_path = os.path.join(project_path, 'data/answers')\n",
    "questions_input_path = os.path.join(project_path, 'output/questions-transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionsDF = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('path', questions_input_path)\n",
    "    .load()\n",
    ")\n",
    "\n",
    "answersDF = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('path', answers_input_path)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the input data for ALS\n",
    "\n",
    "Hint:\n",
    "* the algorithm assumes a dataframe with 3 cols: user, item, rating\n",
    "    * in our case the item is question_id\n",
    "    * in our case rating is score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = (\n",
    "    questionsDF\n",
    "    .filter(col('accepted_answer_id').isNotNull())\n",
    "    .alias('q')\n",
    "    .join(answersDF.alias('a'), 'question_id')\n",
    "    .select(\n",
    "        \n",
    "        col('a.user_id').alias('user'),\n",
    "        col('question_id').alias('item'),\n",
    "        col('a.score').alias('rating')\n",
    "    )\n",
    "    .filter(col('user').isNotNull())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|  user|  item|rating|\n",
      "+------+------+------+\n",
      "|137842|370385|     1|\n",
      "|   717|  6419|     3|\n",
      "| 47360|396818|     7|\n",
      "|  1492| 41748|     1|\n",
      "| 59406|150238|    18|\n",
      "+------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    questionsDF\n",
    "    .filter(col('accepted_answer_id').isNull())\n",
    "    .alias('q')\n",
    "    .join(answersDF.alias('a'), 'question_id')\n",
    "    .select(\n",
    "        \n",
    "        col('a.user_id').alias('user'),\n",
    "        col('question_id').alias('item'),\n",
    "        col('a.score').alias('rating')\n",
    "    )\n",
    "    .filter(col('user').isNotNull())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|  user|  item|rating|\n",
      "+------+------+------+\n",
      "|211169|437989|     1|\n",
      "|204101|427703|     0|\n",
      "| 26143|109750|     4|\n",
      "| 43351|397644|     4|\n",
      "| 52112|399917|     4|\n",
      "+------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(rank=10, maxIter=5, seed=0)\n",
    "\n",
    "model = als.fit(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = spark.createDataFrame([(7880, )], ['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+\n",
      "|item|recommendations|\n",
      "+----+---------------+\n",
      "+----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.recommendForItemSubset(questions, 5).show(truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------------------------------------------------------------------+\n",
      "|item|                                                                 recommendations|\n",
      "+----+--------------------------------------------------------------------------------+\n",
      "|7880|[[12240, 1.8585068], [29, 1.2806133], [1945, 1.1543533], [2311, 1.0827202], [...|\n",
      "+----+--------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.recommendForItemSubset(questions, 5).show(truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item: integer (nullable = false)\n",
      " |-- recommendations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- user: integer (nullable = true)\n",
      " |    |    |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.recommendForItemSubset(questions, 5).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
