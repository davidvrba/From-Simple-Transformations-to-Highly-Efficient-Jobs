{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical modeling\n",
    "\n",
    "In this notebook we will see how user defined functions can be used for statistical modeling using scipy package. We will also see how to implement Pandas UDF which has better performace than vanilla UDF because it can laverage Apache Arrow under the hood for exchanging the data and vectorized execution that is supported by the scipy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, lit, count, year, pandas_udf\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "from scipy.stats import poisson\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('UDFs II')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "answers_input_path = os.path.join(project_path, 'data/answers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "For each user compute probability that the user is going to answer 5 questions in the next year. Use simple model based on poisson distribution.\n",
    "\n",
    "1. Create a DataFrame with two cols: `user_id`, `answers`, where the second is number of questions the user answered in 2019. (We will use only data for 2019 for the sake of simplicity)\n",
    "2. Implement UDF that will use [poisson](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html) distribution from scipy package to compute the probability that if the user answered n questions in 2019, he will answer 5 questions in 2020\n",
    "3. Implement the UDF again, but this time as Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need answers dataset:\n",
    "\n",
    "answersDF = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('path', answers_input_path)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create input DataFrame\n",
    "\n",
    "* filter anwers for the year 2019\n",
    "* filter for rows where `user_id` is not null\n",
    "* group by user and count to see how many questions the users answered in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define UDF:\n",
    "\n",
    "Hint:\n",
    "* the return type will be float, since we will compute probability\n",
    "* use pmf function of the poisson in scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try it with Pandas\n",
    "\n",
    "* create local Pandas dataframe with input data\n",
    "* use the pass a local Pandas series to poisson to see what it returns\n",
    "\n",
    "Hint:\n",
    "* create a pandas series from pandas dataframe as `local_data['answers']`, where local_data is pd df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It returns numpy array:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily create a pandas series from it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pandas udf:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the UDF:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
