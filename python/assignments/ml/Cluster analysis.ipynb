{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "* create cluster of users based on the information about their location\n",
    "* use location coordinates of places from local postgres database\n",
    "* visualise the result of cluster analysis\n",
    "* save the ml model for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, desc, count, explode\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, MinMaxScaler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('Cluster Analysis I')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "users_input_path = os.path.join(project_path, 'data/users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to jdbc database\n",
    "\n",
    "* We have coordinates of location in local postgres db\n",
    "* Use the following information to connect to the database and read the data as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = 'org.postgresql.Driver'\n",
    "url = 'jdbc:postgresql://localhost/postgres'\n",
    "table = 'public.locations'\n",
    "user = 'postgres'\n",
    "password = 'postgres'\n",
    "\n",
    "# Your code here:\n",
    "\n",
    "locations = (\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersDF = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('path', users_input_path)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bring coordinates to users\n",
    "\n",
    "Hint\n",
    "* join users with locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define ML pipeline\n",
    "\n",
    "Hint:\n",
    "* we will cluster users based on their coordinates\n",
    "* use VectorAssambler to define coordinates as vector\n",
    "* use KMenas for clustering\n",
    "* define Pipeline\n",
    "* fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the clusters:\n",
    "\n",
    "Hint:\n",
    "* apply the model on the data using transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group the data by cluster label\n",
    "\n",
    "Hint\n",
    "* group by predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See what points are in individual clusters\n",
    "\n",
    "Hint\n",
    "* filter for specific cluster and show the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise the result\n",
    "\n",
    "* convert to Pandas dataframe\n",
    "* use geopandas library to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_clusters = predictions.select('users.location', *features_array, 'predictions').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.GeoDataFrame(\n",
    "    local_clusters, \n",
    "    geometry=geopandas.points_from_xy(local_clusters.longitude, local_clusters.latitude)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "ax = world.plot(color='white', edgecolor='black')\n",
    "\n",
    "gdf[gdf['predictions'] == 0].plot(ax=ax, color='green')\n",
    "gdf[gdf['predictions'] == 1].plot(ax=ax, color='blue')\n",
    "gdf[gdf['predictions'] == 2].plot(ax=ax, color='red')\n",
    "gdf[gdf['predictions'] == 3].plot(ax=ax, color='black')\n",
    "gdf[gdf['predictions'] == 4].plot(ax=ax, color='yellow')\n",
    "gdf[gdf['predictions'] == 5].plot(ax=ax, color='violet')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the result back to Postgre\n",
    "\n",
    "Hint:\n",
    "* in postgre there is table user_clusters which has two columns: user_id, cluster_id\n",
    "* append the table with the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
